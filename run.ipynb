{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c224d86",
   "metadata": {},
   "source": [
    "## 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import global_options\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pathlib import Path\n",
    "import stanza\n",
    "from stanza.server import CoreNLPClient\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc79f305",
   "metadata": {},
   "source": [
    "## 2 - Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2653c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(global_options.DATA_FOLDER, \"input\", \"AI_FinancialTimes.csv\"))\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates(subset = 'Article title')\n",
    "\n",
    "# Combine columns into 'full_text' and clean up quotation marks\n",
    "data['full_text'] = data['Article title'] + ' ' + data['Article authors'] + ' ' + data['Full article text']\n",
    "\n",
    "# Select the desired columns\n",
    "data = data[['full_text']]\n",
    "\n",
    "# Replace the newline operator as space\n",
    "data['full_text'] = data['full_text'].str.replace('\\n', ' ', regex = False)\n",
    "\n",
    "#\n",
    "data['index'] = range(1, len(data)+1)\n",
    "\n",
    "# Write to text files\n",
    "with open(Path(global_options.DATA_FOLDER, \"input\", \"documents.txt\"), \"w\") as file_docs:\n",
    "    for _, row in data.iterrows():\n",
    "        file_docs.write(f\"{row['full_text']}\\n\")\n",
    "        \n",
    "with open(Path(global_options.DATA_FOLDER, \"input\", \"document_ids.txt\"), \"w\") as file_docs:\n",
    "    for _, row in data.iterrows():\n",
    "        file_docs.write(f\"{row['index']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebb8fd",
   "metadata": {},
   "source": [
    "## 3 - Run py files to expand the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13df9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:39:59 INFO: Writing properties to tmp file: corenlp_server-3f2e10fe33964cb4.props\n",
      "2024-03-16 00:39:59 INFO: Starting server with command: java -Xmx8G -cp /Users/yuruchen/CoreNLP1/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9003 -timeout 12000000 -threads 2 -maxCharLength 1000000 -quiet False -serverProperties corenlp_server-3f2e10fe33964cb4.props -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:39:59.923125\n",
      "Processing line: 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main] INFO CoreNLP - --- StanfordCoreNLPServer#main() called ---\n",
      "[main] INFO CoreNLP - Server default properties:\n",
      "\t\t\t(Note: unspecified annotator properties are English defaults)\n",
      "\t\t\tannotators = tokenize, ssplit, pos, lemma, ner, depparse\n",
      "\t\t\tinputFormat = text\n",
      "\t\t\tner.applyFineGrained = false\n",
      "\t\t\toutputFormat = serialized\n",
      "\t\t\tprettyPrint = false\n",
      "\t\t\tthreads = 2\n",
      "[main] INFO CoreNLP - Threads: 2\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words-distsim.tagger ... done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.NERCombinerAnnotator - numeric classifiers: true; SUTime: true [no docDate]; fine grained: false\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... Time elapsed: 1.5 sec\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 20000 vectors, elapsed Time: 0.848 sec\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [2.4 sec].\n",
      "[main] INFO CoreNLP - Starting server...\n",
      "[main] INFO CoreNLP - StanfordCoreNLPServer listening at /0:0:0:0:0:0:0:0:9003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:44:05.610448\n",
      "Processing line: 200.\n",
      "2024-03-16 00:49:52.454312\n",
      "Processing line: 300.\n",
      "2024-03-16 00:55:30.997653\n",
      "Processing line: 400.\n",
      "2024-03-16 01:00:53.280133\n",
      "Processing line: 500.\n",
      "2024-03-16 01:06:53.744023\n",
      "Processing line: 600.\n",
      "2024-03-16 01:12:24.276245\n",
      "Processing line: 700.\n",
      "2024-03-16 01:17:44.092840\n",
      "Processing line: 800.\n",
      "2024-03-16 01:22:41.227862\n",
      "Processing line: 900.\n",
      "2024-03-16 01:27:47.043831\n",
      "Processing line: 1000.\n",
      "2024-03-16 01:32:56.544332\n",
      "Processing line: 1100.\n",
      "2024-03-16 01:38:57.896836\n",
      "Processing line: 1200.\n",
      "2024-03-16 01:45:42.919293\n",
      "Processing line: 1300.\n",
      "2024-03-16 01:51:30.720173\n",
      "Processing line: 1400.\n",
      "2024-03-16 01:57:03.028715\n",
      "Processing line: 1500.\n",
      "2024-03-16 02:02:36.684644\n",
      "Processing line: 1600.\n",
      "2024-03-16 02:08:08.130982\n",
      "Processing line: 1700.\n",
      "2024-03-16 02:13:32.767848\n",
      "Processing line: 1800.\n",
      "2024-03-16 02:18:45.701248\n",
      "Processing line: 1900.\n",
      "2024-03-16 02:24:46.288262\n",
      "Processing line: 2000.\n",
      "2024-03-16 02:31:27.610431\n",
      "Processing line: 2100.\n",
      "2024-03-16 02:38:26.114972\n",
      "Processing line: 2200.\n",
      "2024-03-16 02:45:41.882738\n",
      "Processing line: 2300.\n",
      "2024-03-16 02:51:36.454482\n",
      "Processing line: 2400.\n",
      "2024-03-16 02:57:27.491636\n",
      "Processing line: 2500.\n",
      "2024-03-16 03:04:07.307205\n",
      "Processing line: 2600.\n",
      "2024-03-16 03:09:57.219193\n",
      "Processing line: 2700.\n",
      "2024-03-16 03:15:27.706447\n",
      "Processing line: 2800.\n",
      "2024-03-16 03:21:41.273148\n",
      "Processing line: 2900.\n",
      "2024-03-16 03:28:34.144284\n",
      "Processing line: 3000.\n",
      "2024-03-16 03:34:04.162499\n",
      "Processing line: 3100.\n",
      "2024-03-16 03:39:25.100445\n",
      "Processing line: 3200.\n",
      "2024-03-16 03:44:30.207834\n",
      "Processing line: 3300.\n",
      "2024-03-16 03:49:34.402059\n",
      "Processing line: 3400.\n",
      "2024-03-16 03:54:38.975860\n",
      "Processing line: 3500.\n",
      "2024-03-16 03:59:48.747450\n",
      "Processing line: 3600.\n",
      "2024-03-16 04:03:59.616169\n",
      "Processing line: 3700.\n",
      "2024-03-16 04:07:28.970322\n",
      "Processing line: 3800.\n",
      "2024-03-16 04:12:58.890735\n",
      "Processing line: 3900.\n",
      "2024-03-16 04:18:20.298604\n",
      "Processing line: 4000.\n",
      "2024-03-16 04:23:06.006651\n",
      "Processing line: 4100.\n",
      "2024-03-16 04:28:54.704421\n",
      "Processing line: 4200.\n",
      "2024-03-16 04:34:48.223280\n",
      "Processing line: 4300.\n",
      "2024-03-16 04:41:07.157734\n",
      "Processing line: 4400.\n",
      "2024-03-16 04:46:48.341097\n",
      "Processing line: 4500.\n",
      "2024-03-16 04:52:43.500554\n",
      "Processing line: 4600.\n",
      "2024-03-16 04:58:00.948875\n",
      "Processing line: 4700.\n",
      "2024-03-16 05:02:57.061252\n",
      "Processing line: 4800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Thread-0] INFO CoreNLP - CoreNLP Server is shutting down.\n"
     ]
    }
   ],
   "source": [
    "%run parse_parallel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f590ab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 10:57:07.357413\n",
      "Processing line: 200000.\n",
      "2024-03-16 10:57:16.494286\n",
      "Processing line: 400000.\n",
      "2024-03-16 10:57:21.597032\n",
      "Training phraser...\n",
      "DEBUG:gensim.models.word2vec:single file given as source, rather than a directory of files\n",
      "DEBUG:gensim.models.word2vec:consider using models.word2vec.LineSentence for a single file\n",
      "INFO:gensim.models.word2vec:files read into PathLineSentences:data/processed/unigram/documents.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                | 0/303123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:reading file data/processed/unigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/unigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.phrases:PROGRESS: at sentence #0, processed 0 words and 0 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▌                                 | 5468/303123 [00:00<00:05, 54573.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #10000, processed 96497 words and 78812 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█▉                               | 18243/303123 [00:00<00:04, 60660.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #20000, processed 199073 words and 146239 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██▋                              | 24311/303123 [00:00<00:04, 56463.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #30000, processed 302464 words and 210179 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███▉                             | 36567/303123 [00:00<00:04, 59173.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #40000, processed 402044 words and 266829 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████▎                           | 48376/303123 [00:00<00:04, 53661.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #50000, processed 509924 words and 323851 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████▍                          | 59202/303123 [00:01<00:04, 51179.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #60000, processed 615759 words and 378116 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|███████                          | 64601/303123 [00:01<00:04, 51975.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #70000, processed 711286 words and 431137 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████▎                        | 76271/303123 [00:01<00:04, 52548.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #80000, processed 816444 words and 489182 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████▍                       | 86700/303123 [00:01<00:05, 39556.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #90000, processed 928603 words and 551329 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████▍                      | 95769/303123 [00:01<00:05, 41445.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #100000, processed 1037993 words and 610878 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████▏                    | 105791/303123 [00:02<00:04, 45701.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #110000, processed 1147420 words and 668787 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▌                   | 119342/303123 [00:02<00:04, 37218.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #120000, processed 1254216 words and 725082 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████▏                  | 124908/303123 [00:02<00:04, 41933.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #130000, processed 1355721 words and 777022 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████▍                 | 136621/303123 [00:02<00:03, 49784.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #140000, processed 1448085 words and 821925 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████▋                | 148812/303123 [00:03<00:02, 54994.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #150000, processed 1544718 words and 866207 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████▊               | 159716/303123 [00:03<00:02, 51012.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #160000, processed 1655931 words and 920705 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████▉              | 169821/303123 [00:03<00:02, 47178.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #170000, processed 1764866 words and 974556 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████▉             | 179272/303123 [00:03<00:03, 37529.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #180000, processed 1872101 words and 1026980 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████            | 189628/303123 [00:03<00:02, 44101.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #190000, processed 1972616 words and 1073419 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████           | 199858/303123 [00:04<00:02, 46611.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #200000, processed 2073767 words and 1116904 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████          | 209577/303123 [00:04<00:02, 39700.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #210000, processed 2184476 words and 1166236 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████▋         | 214762/303123 [00:04<00:02, 42791.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #220000, processed 2298734 words and 1216786 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████▊        | 225277/303123 [00:04<00:01, 47358.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #230000, processed 2405248 words and 1265856 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████▊       | 235437/303123 [00:04<00:01, 47956.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #240000, processed 2517914 words and 1316205 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████▉      | 245179/303123 [00:05<00:01, 47138.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #250000, processed 2624505 words and 1361544 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████▍    | 259553/303123 [00:05<00:01, 39133.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #260000, processed 2725145 words and 1404096 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████▌   | 269971/303123 [00:05<00:00, 44875.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #270000, processed 2832780 words and 1450014 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████▌  | 279994/303123 [00:05<00:00, 47380.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #280000, processed 2944149 words and 1496993 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████▌ | 289900/303123 [00:06<00:00, 48499.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #290000, processed 3053205 words and 1544760 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████ | 294452/303123 [00:06<00:00, 47066.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collected 1565707 word types from a corpus of 3100326 words (unigram + bigrams) and 294452 sentences\n",
      "INFO:gensim.models.phrases:using 1565707 counts as vocab in Phrases<0 vocab, min_count=10, threshold=10, max_vocab_size=40000000>\n",
      "INFO:gensim.utils:saving Phrases object under models/phrases/bigram.mod, separately None\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/phrases/bigram.mod', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saved models/phrases/bigram.mod\n",
      "INFO:gensim.utils:loading Phrases object from models/phrases/bigram.mod\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/phrases/bigram.mod', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:loaded models/phrases/bigram.mod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 303123/303123 [00:13<00:00, 22350.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 10:57:46.921195\n",
      "Training phraser...\n",
      "DEBUG:gensim.models.word2vec:single file given as source, rather than a directory of files\n",
      "DEBUG:gensim.models.word2vec:consider using models.word2vec.LineSentence for a single file\n",
      "INFO:gensim.models.word2vec:files read into PathLineSentences:data/processed/bigram/documents.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                | 0/303123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:reading file data/processed/bigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/bigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.phrases:PROGRESS: at sentence #0, processed 0 words and 0 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▋                                 | 5705/303123 [00:00<00:05, 57038.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #10000, processed 92000 words and 79750 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██                               | 19200/303123 [00:00<00:04, 65070.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #20000, processed 189530 words and 148769 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██▊                              | 25708/303123 [00:00<00:04, 63500.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #30000, processed 288277 words and 214449 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▏                            | 38444/303123 [00:00<00:04, 62321.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #40000, processed 383316 words and 272958 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████▊                            | 44686/303123 [00:00<00:04, 60553.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #50000, processed 485916 words and 332070 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████▏                          | 56714/303123 [00:00<00:04, 57569.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #60000, processed 586794 words and 388380 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████▍                         | 68228/303123 [00:01<00:04, 56771.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #70000, processed 678992 words and 443091 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████                         | 74447/303123 [00:01<00:03, 58364.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #80000, processed 780120 words and 502999 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████▎                       | 85783/303123 [00:01<00:04, 52841.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #90000, processed 888066 words and 567110 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████▌                      | 96699/303123 [00:01<00:03, 53696.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #100000, processed 993717 words and 628591 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████▎                    | 107405/303123 [00:01<00:03, 51743.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #110000, processed 1099487 words and 688590 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▍                   | 117577/303123 [00:02<00:03, 47511.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #120000, processed 1202928 words and 746783 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████▌                  | 128608/303123 [00:02<00:03, 51303.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #130000, processed 1301097 words and 800476 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████▏                 | 134277/303123 [00:02<00:03, 52859.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #140000, processed 1390486 words and 846990 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████▍                | 146047/303123 [00:02<00:02, 55740.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #150000, processed 1483859 words and 892838 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████▌               | 157211/303123 [00:02<00:02, 52654.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #160000, processed 1591188 words and 949400 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████▋              | 167820/303123 [00:03<00:02, 50949.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #170000, processed 1696456 words and 1005205 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████▊             | 178688/303123 [00:03<00:02, 52087.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #180000, processed 1799907 words and 1059614 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|███████████████████▍            | 184085/303123 [00:03<00:02, 52634.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #190000, processed 1896784 words and 1107985 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████▋           | 195889/303123 [00:03<00:01, 55744.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #200000, processed 1993719 words and 1153631 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████▊          | 207132/303123 [00:03<00:01, 55703.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #210000, processed 2099784 words and 1205271 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████▉         | 217756/303123 [00:04<00:01, 49160.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #220000, processed 2209349 words and 1258199 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████        | 227852/303123 [00:04<00:01, 49284.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #230000, processed 2311996 words and 1308999 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████       | 237810/303123 [00:04<00:01, 44585.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #240000, processed 2419957 words and 1361532 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████      | 247427/303123 [00:04<00:01, 45842.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #250000, processed 2521978 words and 1408959 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████▏    | 257328/303123 [00:04<00:01, 41215.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #260000, processed 2618716 words and 1453398 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████▏   | 267282/303123 [00:05<00:00, 45070.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #270000, processed 2722156 words and 1501266 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████▎  | 277695/303123 [00:05<00:00, 48505.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #280000, processed 2828961 words and 1550273 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████▍ | 288243/303123 [00:05<00:00, 50132.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #290000, processed 2933932 words and 1600200 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████ | 294452/303123 [00:05<00:00, 51901.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collected 1622145 word types from a corpus of 2979547 words (unigram + bigrams) and 294452 sentences\n",
      "INFO:gensim.models.phrases:using 1622145 counts as vocab in Phrases<0 vocab, min_count=10, threshold=10, max_vocab_size=40000000>\n",
      "INFO:gensim.utils:saving Phrases object under models/phrases/trigram.mod, separately None\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/phrases/trigram.mod', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saved models/phrases/trigram.mod\n",
      "INFO:gensim.utils:loading Phrases object from models/phrases/trigram.mod\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/phrases/trigram.mod', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:loaded models/phrases/trigram.mod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 303123/303123 [00:12<00:00, 24205.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 10:58:11.037366\n",
      "Training w2v model...\n",
      "DEBUG:gensim.models.word2vec:single file given as source, rather than a directory of files\n",
      "DEBUG:gensim.models.word2vec:consider using models.word2vec.LineSentence for a single file\n",
      "INFO:gensim.models.word2vec:files read into PathLineSentences:data/processed/trigram/documents.txt\n",
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 90817 words, keeping 15131 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 186986 words, keeping 23953 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 284609 words, keeping 31471 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 378502 words, keeping 37295 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 479738 words, keeping 43023 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 579376 words, keeping 48196 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 670841 words, keeping 53400 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 771072 words, keeping 59168 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 878057 words, keeping 65545 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 982976 words, keeping 71512 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 1088075 words, keeping 77238 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 1190981 words, keeping 82472 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 1288526 words, keeping 87274 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 1377377 words, keeping 91194 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 1469995 words, keeping 95121 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 1576494 words, keeping 99998 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 1681000 words, keeping 104857 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 1783706 words, keeping 109613 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 1879803 words, keeping 113622 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 1975796 words, keeping 117535 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 2080713 words, keeping 122282 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 2189282 words, keeping 127172 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 2290817 words, keeping 132869 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 2397633 words, keeping 137760 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 2498546 words, keeping 141861 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 2594313 words, keeping 145579 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 2696654 words, keeping 149670 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 2802215 words, keeping 154093 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 2906390 words, keeping 158226 word types\n",
      "INFO:gensim.models.word2vec:collected 159995 word types from a corpus of 2951787 raw words and 294452 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 retains 26710 unique words (16% of original 159995, drops 133285)\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 leaves 2773359 word corpus (93% of original 2951787, drops 178428)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 159995 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 28 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 2388420 word corpus (86.1% of prior 2773359)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 26710 words and 300 dimensions: 77459000 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 2 workers on 26710 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 12.91% examples, 288976 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 33.52% examples, 389041 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 45.36% examples, 348227 words/s, in_qsize 3, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 65.99% examples, 381310 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 85.25% examples, 398595 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 2951787 raw words (2389090 effective words) took 5.9s, 405470 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 21.42% examples, 490726 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 40.03% examples, 466746 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 56.02% examples, 433782 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 76.67% examples, 450744 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 93.66% examples, 433201 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 2951787 raw words (2388702 effective words) took 5.5s, 435977 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 21.10% examples, 480931 words/s, in_qsize 3, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 38.68% examples, 424605 words/s, in_qsize 4, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 63.71% examples, 476048 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 87.74% examples, 486419 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 2951787 raw words (2388388 effective words) took 4.8s, 495110 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 25.84% examples, 554617 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 41.02% examples, 464742 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 54.11% examples, 409362 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 68.40% examples, 391053 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 80.92% examples, 373687 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 91.10% examples, 349357 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 2951787 raw words (2388561 effective words) took 7.1s, 334564 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 14.33% examples, 320965 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 33.52% examples, 370427 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 52.80% examples, 396074 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 73.74% examples, 424317 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 88.42% examples, 409330 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 2951787 raw words (2389077 effective words) took 5.9s, 407273 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 21.10% examples, 480342 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 35.80% examples, 418484 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 54.74% examples, 425955 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 75.68% examples, 445638 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 90.80% examples, 427255 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 6 : training on 2951787 raw words (2388345 effective words) took 5.6s, 428830 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 22.89% examples, 520212 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 38.02% examples, 440163 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 59.04% examples, 457275 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 78.34% examples, 439705 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 97.86% examples, 444608 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 7 : training on 2951787 raw words (2388174 effective words) took 5.4s, 445885 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 21.76% examples, 498391 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 36.42% examples, 425784 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 56.70% examples, 443248 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 72.18% examples, 423700 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 91.11% examples, 429315 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 8 : training on 2951787 raw words (2388503 effective words) took 5.5s, 436534 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 19.41% examples, 401526 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 37.70% examples, 420267 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 59.04% examples, 444187 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 75.33% examples, 429807 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 95.98% examples, 440116 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 9 : training on 2951787 raw words (2388859 effective words) took 5.4s, 443288 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 17.66% examples, 401330 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 35.47% examples, 412581 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 56.70% examples, 440163 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 75.00% examples, 441506 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 93.66% examples, 441617 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 10 : training on 2951787 raw words (2388961 effective words) took 5.4s, 442257 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 17.64% examples, 404088 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 35.80% examples, 418742 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 56.70% examples, 442538 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 71.55% examples, 419560 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 90.49% examples, 424050 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 11 : training on 2951787 raw words (2388125 effective words) took 5.5s, 431469 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 16.65% examples, 379142 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 34.84% examples, 406975 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 56.02% examples, 437708 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 71.55% examples, 417942 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 90.49% examples, 424259 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 12 : training on 2951787 raw words (2388755 effective words) took 5.5s, 432444 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 18.00% examples, 401848 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 36.42% examples, 422353 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 56.70% examples, 440873 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 73.74% examples, 432977 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 91.41% examples, 430190 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 13 : training on 2951787 raw words (2388353 effective words) took 5.5s, 436063 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 18.00% examples, 408601 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 35.47% examples, 414018 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 56.02% examples, 437066 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 73.44% examples, 433559 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 92.08% examples, 434454 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 14 : training on 2951787 raw words (2389080 effective words) took 5.4s, 439542 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 17.64% examples, 403977 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 34.51% examples, 403036 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 55.70% examples, 434486 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 74.08% examples, 437597 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 92.42% examples, 436497 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 15 : training on 2951787 raw words (2388069 effective words) took 5.4s, 438633 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 17.30% examples, 382903 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 36.12% examples, 415227 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 54.11% examples, 414419 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 72.82% examples, 423107 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 92.74% examples, 433609 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 16 : training on 2951787 raw words (2388175 effective words) took 5.5s, 436395 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 19.07% examples, 436019 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 36.12% examples, 420276 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 50.62% examples, 389344 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 68.73% examples, 401900 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 90.18% examples, 423138 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 17 : training on 2951787 raw words (2389198 effective words) took 5.8s, 411818 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 19.07% examples, 429487 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 38.69% examples, 452467 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 54.74% examples, 423230 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 73.11% examples, 429139 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 92.40% examples, 423331 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 18 : training on 2951787 raw words (2388522 effective words) took 5.7s, 419625 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 20.07% examples, 455965 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 39.72% examples, 462505 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 55.70% examples, 432116 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 78.03% examples, 458786 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 93.66% examples, 440710 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 148 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 19 : training on 2951787 raw words (2388409 effective words) took 5.4s, 443602 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 18.36% examples, 413651 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 33.84% examples, 365192 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 53.77% examples, 392880 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 71.87% examples, 403058 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 87.74% examples, 397872 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 296 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 147 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 149 jobs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 20 : training on 2951787 raw words (2389125 effective words) took 6.0s, 400979 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 59035740 raw words (47772471 effective words) took 112.2s, 425746 effective words/s\n",
      "INFO:gensim.utils:saving Word2Vec object under models/w2v/w2v.mod, separately None\n",
      "INFO:gensim.utils:not storing attribute vectors_norm\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/w2v/w2v.mod', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:saved models/w2v/w2v.mod\n"
     ]
    }
   ],
   "source": [
    "%run clean_and_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefdb53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size in the w2v model: 26710\n",
      "Dictionary created. \n",
      "Dictionary deduplicated. \n",
      "Dictionary saved at outputs/dict/expanded_dict.csv\n"
     ]
    }
   ],
   "source": [
    "%run create_dict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829426b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
